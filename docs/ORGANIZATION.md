# Repository Organization

> **For complete project details, see the [published journal article](https://link.springer.com/article/10.1007/s42979-026-04744-9).**

---

## Quick Overview

```
7-Emotion-Bangla-Speech-Recognition-Model/
â”œâ”€â”€ README.md                    â† Start here
â”œâ”€â”€ RESEARCH.md                  â† Research overview
â”‚
â”œâ”€â”€ emotion-detection/           â† Main Flask + React app (web version)
â”‚   â”œâ”€â”€ backend/                 (Server, models)
â”‚   â””â”€â”€ src/                     (React frontend)
â”‚
â”œâ”€â”€ emotion-detection-raspi/     â† Raspberry Pi optimized version
â”‚   â”œâ”€â”€ backend/
â”‚   â””â”€â”€ src/
â”‚
â”œâ”€â”€ research/
â”‚   â””â”€â”€ experiments/             â† Jupyter notebooks (all experiments)
â”‚       â””â”€â”€ Final CNN + BiLSTM.ipynb  (â­ FINAL MODEL)
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ SETUP.md                 â† Installation guide
â”‚   â”œâ”€â”€ ARCHITECTURE.md          â† Model design
â”‚   â”œâ”€â”€ RESULTS.md               â† Performance metrics
â”‚   â””â”€â”€ ORGANIZATION.md          â† This file
â”‚
â”œâ”€â”€ archived/                    â† Old notebooks, datasets & experiments
â”‚   â”œâ”€â”€ old_notebooks/
â”‚   â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ deprecated/
â”‚
â””â”€â”€ images/                      â† Diagrams & visualizations
    â”œâ”€â”€ Project Workflow.png
    â”œâ”€â”€ Architecture.png
    â”œâ”€â”€ Confusion Matrix.png
    â””â”€â”€ [others]
```

---

## Key Files Explained

### Documentation  
- **README.md** - Project overview, quick start
- **RESEARCH.md** - Research questions and findings  
- **docs/SETUP.md** - Installation and deployment  
- **docs/ARCHITECTURE.md** - Model specifications  
- **docs/RESULTS.md** - Performance summary

### Production Code  
- **emotion-detection/** - Web application (Flask + React)
- **emotion-detection-raspi/** - Raspberry Pi version
- **research/experiments/Final CNN + BiLSTM.ipynb** - Training code

### Supporting  
- **archived/datasets/** - Dataset information (BanglaMOOD versions)  
- **archived/** - Historical experiments  
- **images/** - Visual diagrams

---

## Which Folder Do I Need?

| Need                          | Go To |
|-------------------------------|-------|
| Deploy web app                | `deployments/emotion-detection/` |
| Deploy on Raspberry Pi        | `deployments/emotion-detection-raspi/` |
| Train model from scratch      | `research/experiments/` |
| Understand architecture       | `docs/ARCHITECTURE.md` |
| See results                   | `docs/RESULTS.md` |
| Install & setup               | `docs/SETUP.md` |

---

## For Details

ğŸ“– **[Full Journal Article](https://link.springer.com/article/10.1007/s42979-026-04744-9)** - Complete documentation

---

**Last Updated:** February 2026

```
emotion-detection/
â”œâ”€â”€ backend/                           # Flask server
â”‚   â”œâ”€â”€ app.py                         # Main Flask application
â”‚   â”œâ”€â”€ model.py                       # CNN-BiLSTM model architecture
â”‚   â”œâ”€â”€ realtimetest.py               # Real-time testing utilities
â”‚   â”œâ”€â”€ requirements.txt               # Python dependencies
â”‚   â”œâ”€â”€ __pycache__/                  # Compiled Python files
â”‚   â”‚
â”‚   â”œâ”€â”€ Models (Pre-trained)
â”‚   â”œâ”€â”€ bangla_emotion_model.pth      # Standard model
â”‚   â”œâ”€â”€ bangla_emotion_model_incremental.pth  # For incremental learning
â”‚   â”œâ”€â”€ Final_MultiScale_Realtime_Model.pth   # â­ FINAL/BEST MODEL
â”‚   â””â”€â”€ strict_excitement_detector.pth        # Specialized model
â”‚   
â”‚   â””â”€â”€ cert/                         # SSL certificates
â”‚
â”œâ”€â”€ src/                              # React frontend
â”‚   â”œâ”€â”€ App.js                        # Main React component
â”‚   â”œâ”€â”€ App.css                       # Styling
â”‚   â”œâ”€â”€ index.js                      # Entry point
â”‚   â”œâ”€â”€ components/                   # React components
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ index.html                   # HTML template
â”‚   â”œâ”€â”€ manifest.json                # PWA manifest
â”‚   â””â”€â”€ robots.txt
â”‚
â”œâ”€â”€ package.json                     # Node.js dependencies
â”œâ”€â”€ package-lock.json
â””â”€â”€ README.md                        # Frontend-specific README
```

**What It Does:**
- Web-based emotion detection system
- Real-time audio capture and emotion classification
- Integration with LLM for emotion-aware responses
- Counseling session interface
- Incremental learning interface
- Testing interface for emotion detection

**How to Run:**
```bash
cd deployments/emotion-detection
cd backend && python app.py
# In another terminal:
npm start
```

### deployments/emotion-detection-raspi/
**Raspberry Pi optimized version of the above**

```
emotion-detection-raspi/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                       # Flask (Pi-optimized)
â”‚   â”œâ”€â”€ model.py                     # Same model as main
â”‚   â”œâ”€â”€ start_flask_app.sh           # Startup script for Pi
â”‚   â”œâ”€â”€ Final_MultiScale_Realtime_Model.pth
â”‚   â”œâ”€â”€ requirements-pi.txt          # Pi-specific dependencies
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ src/                             # React frontend (same)
â”œâ”€â”€ public/                          # Static files (same)
â”œâ”€â”€ debug_react_start.sh             # Debug startup script
â””â”€â”€ start_react_app.sh               # Production startup script
```

**What It Does:**
- Same functionality as main emotion-detection
- Optimized for Raspberry Pi 4B hardware
- Lower memory footprint
- Startup scripts for automated deployment

**How to Run:**
```bash
cd deployments/emotion-detection-raspi/backend
bash start_flask_app.sh
```

---

## ğŸ“ research/ - Research Artifacts

Experimental notebooks and analysis from the research process.

### research/experiments/
**Jupyter notebooks showing each experiment step-by-step**

```
research/experiments/
â”œâ”€â”€ Final CNN + BiLSTM.ipynb                    # â­ BEST MODEL CODE
â”‚   â””â”€â”€ Contains: Complete training code for final model
â”‚
â”œâ”€â”€ Real Time Final/
â”‚   â”œâ”€â”€ BanglaMOOD + KUET.ipynb                # Multi-dataset experiment
â”‚   â”œâ”€â”€ Final CNN + BiLSTM.ipynb               # Same as above
â”‚   â”œâ”€â”€ SER_SOTA_Benchmark.ipynb               # Benchmark comparisons
â”‚   â”œâ”€â”€ SER_SOTA_Benchmark (1).ipynb          
â”‚   â”œâ”€â”€ SER_SOTA_Benchmark (2).ipynb
â”‚   â”œâ”€â”€ SUBESCO + BanglaMOOD + KUET.ipynb     # Dataset combination study
â”‚   â””â”€â”€ SUBESCO + BANSpEmo + BanglaSER.ipynb  # Final dataset mix
â”‚
â”œâ”€â”€ CSE499 BanglaMOOD Pytorch v2.ipynb         # Early experiments (v2)
â”œâ”€â”€ CSE499 BanglaMOOD Pytorch v3 Augmentation.ipynb  # v3 with augmentation
â”œâ”€â”€ CSE499 BanglaMOOD Pytorch v4 257sample.ipynb     # v4 with 257 samples
â”œâ”€â”€ CSE499 BanglaMOOD Pytorch v5 257sample Fix.ipynb # v5 fixes
â”œâ”€â”€ CSE499 BanglaMOOD Pytorch.ipynb            # Original version
â”‚
â”œâ”€â”€ Pytorch Improvement-Copy1.ipynb            # Improvement iterations
â”œâ”€â”€ Pytorch Improvement-Copy2.ipynb
â”œâ”€â”€ Pytorch Improvement-Copy3.ipynb
â”œâ”€â”€ Pytorch Improvement.ipynb
â”‚
â”œâ”€â”€ PytorchEditionFear86%.ipynb                # Specialized model
â”œâ”€â”€ Remove background noise.ipynb              # Audio preprocessing
â”‚
â””â”€â”€ CSE499_Speech_Recognition - [Various versions]  # TensorFlow experiments
    â”œâ”€â”€ Pytorch Edition - Merged - AudioReduced.ipynb
    â”œâ”€â”€ Pytorch Edition - Merged - AudioReduced-Copy1.ipynb
    â””â”€â”€ Tensorflow Edition - [Various versions]
```

**Purpose:**
- Document research journey
- Show model evolution
- Provide reproducible experiment code
- Educational value for understanding design choices

**Which notebooks to examine:**
- **Best Model:** `Final CNN + BiLSTM.ipynb`
- **Benchmarks:** `SER_SOTA_Benchmark*.ipynb`
- **Dataset Studies:** `SUBESCO + ... notebooks`

### research/datasets/
**Dataset information and preprocessed data references**

```
research/datasets/
â”œâ”€â”€ BanglaMOOD v1/
â”‚   â””â”€â”€ Score.txt                    # Experiment 1 results
â”‚
â”œâ”€â”€ BanglaMOOD v2/
â”‚   â””â”€â”€ Scores.txt                   # Experiment 2 results
â”‚
â”œâ”€â”€ BanglaMOOD v3 685 samples each/
â”‚   â””â”€â”€ Score.txt                    # Version 3 (685 samples per emotion)
â”‚
â”œâ”€â”€ BanglaMOOD v4 257 samples each/
â”‚   â””â”€â”€ Score.txt                    # Version 4 (257 samples) - used in final
â”‚
â””â”€â”€ DATASET_INFO.md                  # Meta-information about all datasets
```

**Contents:**
- Dataset version history
- Sample counts per emotion
- Data splits (train/val/test)
- Preprocessing information

---

## ğŸ“ docs/ - Technical Documentation

Detailed technical documentation for developers and researchers.

```
docs/
â”œâ”€â”€ ARCHITECTURE.md                  # Model architecture details
â”‚   â””â”€â”€ Layer specifications, hyperparameters, design decisions
â”‚
â”œâ”€â”€ SETUP.md                        # Installation & setup guide
â”‚   â””â”€â”€ Prerequisites, installation steps, troubleshooting, Docker
â”‚
â”œâ”€â”€ RESULTS.md                      # Detailed experimental results
â”‚   â””â”€â”€ All 5 experiments with metrics, confusion matrices, visualizations
â”‚
â”œâ”€â”€ INCREMENTAL_LEARNING.md         # Incremental learning guide (if exists)
â”‚   â””â”€â”€ How to use incremental learning, API reference
â”‚
â””â”€â”€ API_REFERENCE.md                # Flask API endpoints (if exists)
    â””â”€â”€ Available endpoints, request/response formats
```

---

## ğŸ“Š Output & Results Files

### At Root Level (Can Move to Archive)
- **output1.txt** - Original research journal summary
- **output2.txt** - Original ICCIT paper abstract

**These are now documented in:**
- RESEARCH.md (comprehensive)
- README.md (summary)

---

## .gitignore - Files to Exclude

Typical files to exclude from version control:

```
# Python
__pycache__/
*.py[cod]
*.egg-info/
.env
venv/
env/

# Node/npm
node_modules/
npm-debug.log
.npm

# Models (too large)
*.pth
*.h5
*.ckpt

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Jupyter
.ipynb_checkpoints/
*.ipynb_checkpoints

# Data (large)
data/
datasets/
*.wav
*.mp3
```

---

## How to Navigate This Repository

### ğŸ‘¤ For New Users / Visitors
1. Read: **README.md** (5 min overview)
2. Check: **RESEARCH.md** (understand the approach)
3. Try: **emotion-detection/** (run the app)

### ğŸ”¬ For Researchers
1. Read: **RESEARCH.md** (methodology)
2. Review: **docs/RESULTS.md** (experiment details)
3. Study: **docs/ARCHITECTURE.md** (technical details)
4. Examine: **research/experiments/Final CNN + BiLSTM.ipynb**

### ğŸ› ï¸ For Developers
1. Setup: Follow **docs/SETUP.md**
2. Deploy: Use **emotion-detection/**
3. Reference: Check **docs/ARCHITECTURE.md** for model details
4. Test: Use **realtimetest.py** in backend

### ğŸ“š For Students / Learning
1. Start: Git-clone, read README
2. Understand: RESEARCH.md (background)
3. Experiment: Jupyter notebooks in **research/experiments/**
4. Build: Use `emotion-detection/` as a template for your own systems

---

## Recommended Cleanup Actions

### Safe to Delete
These are duplicates or development artifacts that can be removed:

```
# Root level (move to archive/ folder instead)
- output1.txt          â†’ Documented in RESEARCH.md
- output2.txt          â†’ Documented in RESEARCH.md
- best_model.pth       â†’ Use Final_MultiScale_Realtime_Model.pth
- best_modelPytorch.pth â†’ Use Final_MultiScale_Realtime_Model.pth
- cnn-transformer.h5   â†’ Deprecated TensorFlow model
- CSE499_Model.pth     â†’ Old checkpoint

# Experiment notebooks with redundant versions
- CSE499 BanglaMOOD Pytorch v2-v5 series  â†’ Keep only v5
- Pytorch Improvement-Copy[1-3].ipynb      â†’ Keep only main version
- CSE499_Speech_Recognition (TensorFlow versions) â†’ Keep reference, remove duplicates
```

### Recommended Folder to Create
```
archived/
â”œâ”€â”€ output1.txt
â”œâ”€â”€ output2.txt
â”œâ”€â”€ old_models/
â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”œâ”€â”€ best_modelPytorch.pth
â”‚   â”œâ”€â”€ cnn-transformer.h5
â”‚   â””â”€â”€ CSE499_Model.pth
â””â”€â”€ README.md  (explaining what's in here)
```

---

## Version Control Recommendations

### Branch Structure
```
main/master
  â”œâ”€â”€ stable (production code)
  â”‚   â””â”€â”€ demos & docs
  â”‚
  â””â”€â”€ develop
      â””â”€â”€ experimental features
```

### Commit Messages Convention
```
[CATEGORY] Description

Categories:
- [DOCS] - Documentation updates
- [FEATURE] - New feature
- [FIX] - Bug fix
- [CLEANUP] - Code cleanup
- [EXPERIMENT] - Research notebook
- [DEPLOY] - Deployment updates
```

---

## File Size Guidelines

Keep repository manageable:

| Type | Limit | Action |
|------|-------|--------|
| Single file | <100MB | Track normally |
| Model files | >100MB | Use Git LFS or cloud storage |
| Dataset files | >1GB | Provide download links, not in repo |
| Notebook files | >50MB | Compress or link to cloud |

---

## Maintenance Checklist

- [ ] Update README if features change
- [ ] Keep RESEARCH.md synchronized with papers
- [ ] Test deployment before releasing
- [ ] Update docs/ when model changes
- [ ] Tag releases with version numbers
- [ ] Maintain archived/ folder for old files
- [ ] Update .gitignore as needed
- [ ] Review dependencies regularly

---

## Quick Reference: Key Files

| File | Purpose | Audience |
|------|---------|----------|
| README.md | Project overview | Everyone |
| RESEARCH.md | Research details | Researchers, students |
| docs/ARCHITECTURE.md | Technical details | Developers |
| docs/SETUP.md | Installation | Developers |
| docs/RESULTS.md | Experiment results | Researchers |
| emotion-detection/ | Production app | Users, developers |
| research/experiments/ | Experiment code | Researchers, students |

---

## Further Reading

- For more details on experiments: See RESEARCH.md
- For architecture questions: See docs/ARCHITECTURE.md
- For running the system: See docs/SETUP.md
- For detailed results: See docs/RESULTS.md

---


